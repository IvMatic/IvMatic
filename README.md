## Hi there ğŸ‘‹

# Hi, I'm [Your Name] ğŸ‘‹

I'm interested in **AI interpretability** and **AI safety**.

### What I'm working on
- ğŸ” Reproducing interpretability papers with open models
- ğŸ§ª Small experiments on robustness & safety
- ğŸ“š Notes on interpretability & alignment literature

### Selected projects
- [Project 1: Attention Visualization in Transformers](https://github.com/yourname/attention-viz)
- [Project 2: Toy Safety Experiments with LLM Prompts](https://github.com/yourname/llm-safety-toys)

